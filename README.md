# ai-context
Этот pet-проект сделан, как собственный взгляд на идеи О.Чекирова. Изначальная идея принадлежит ему, я лишь попробовал реализовать её:)
Локальный CLI-инструмент для автоматического сбора контекста кодовой базы и взаимодействия с ИИ-моделью в контексте проекта.


---

## 1. Цель

Создать **локальный, языконезависимый CLI-инструмент**, который:
- автоматически анализирует структуру и содержимое проекта,
- поддерживает актуальный контекст в реальном времени,
- позволяет вести диалог с ИИ-моделью (локальной или облачной), передавая ей **полный контекст проекта**,
- предназначен в первую очередь для личного использования, с возможностью публикации как open-source.

---

## 2. Целевая аудитория

- Автор проекта (основной пользователь),
- Коллеги по команде,
- В будущем — open-source сообщество (разработчики всех уровней).

Поддержка **любых языков программирования и структур проектов**.

---

## 3. Основные требования

### 3.1. Инициализация (`ai-context init`)
- Создаёт скрытую папку `.ai-context/` в корне проекта.
- Автоматически добавляет `.ai-context/` в `.gitignore` (создаёт файл, если отсутствует).
- Генерирует:
    - `.ai-context/.ai-ignore` — правила исключения файлов (аналог `.gitignore`),
    - `.ai-context/secrets.json` — для хранения API-ключей (не коммитится!),
    - `.ai-context/system-prompt.txt` — системный промт для ИИ,
    - `.ai-context/dialog.json` — история диалога,
    - `.ai-context/context.txt` — текстовый файл с контекстом (временно, для отладки).

### 3.2. Индексация проекта (`ai-context index`)
- Сканирует проект рекурсивно.
- Учитывает `.ai-context/.ai-ignore`.
- Пропускает:
    - бинарные файлы,
    - файлы > 1 МБ,
    - скрытые файлы/папки (если не разрешены в `.ai-ignore`).
- Записывает содержимое всех подходящих файлов в единый текстовый файл `context.txt` (формат: `### FILE: path ###` + содержимое).
- На этапе отладки — текстовый файл. В будущем — SQLite.

### 3.3. Интерактивный чат (`ai-context chat`)
- Запускает интерактивный режим в терминале.
- При каждом запросе:
    - читает актуальный контекст (`context.txt`),
    - загружает системный промт (`system-prompt.txt`),
    - добавляет историю диалога (с ограничением по токенам),
    - отправляет запрос в ИИ.
- Поддержка локальных моделей через **Ollama** (OpenAI-совместимый API).
- История сохраняется в `.ai-context/dialog.json`.

### 3.4. Управление промтом (`ai-context prompt`)
- Открывает `system-prompt.txt` в системном редакторе (`$EDITOR`).
- Позволяет настроить стиль, язык и формат ответов ИИ.

### 3.5. Наблюдение за изменениями (`ai-context watch`) — *в разработке*
- В реальном времени отслеживает изменения файлов.
- Автоматически обновляет контекст (только изменённые файлы).
- Использует `watchdog`.

### 3.6. Веб-интерфейс (`ai-context serve`) — *будущее*
- Локальный сервер на FastAPI.
- Веб-чат с возможностью просмотра контекста.

---

## 4. Технический стек (v1)

| Компонент | Технология |
|---------|-----------|
| Язык | Python 3.10+ |
| CLI | Typer + Rich |
| Файловый наблюдатель | watchdog |
| Игнор-правила | pathspec (совместимость с .gitignore) |
| ИИ-клиент | OpenAI Python SDK (с поддержкой Ollama через `base_url`) |
| Хранение контекста (MVP) | Текстовый файл `context.txt` |
| Хранение контекста (v2) | SQLite |
| Упаковка | PyInstaller (Windows, Linux, macOS) |

---

## 5. Поддерживаемые ИИ-модели

- **Основная (MVP)**: локальная модель через **Ollama**  
  → `deepseek-coder:6.7b-instruct` (но архитектура расширяема).
- **Будущее**: OpenAI, Anthropic, Qwen и др.

Клиент использует OpenAI-совместимый API:
```python
base_url = "http://localhost:11434/v1"
api_key = "ollama"