# ai-context

Этот pet-проект сделан как собственный взгляд на идеи О. Чекирова.  
Изначальная идея принадлежит ему — я лишь реализую её на практике.  
Локальный CLI-инструмент для автоматического сбора контекста кодовой базы и взаимодействия с ИИ-моделью **в контексте проекта**.

---

## 1. Цель

Создать **локальный, языконезависимый CLI-инструмент**, который:
- автоматически анализирует структуру и содержимое проекта,
- поддерживает актуальный контекст в реальном времени,
- позволяет вести диалог с ИИ-моделью (локальной или облачной), передавая ей **полный контекст проекта**,
- предназначен в первую очередь для личного использования, с возможностью публикации как open-source.

---

## 2. Целевая аудитория

- Автор проекта (основной пользователь),
- Коллеги по команде,
- В будущем — open-source сообщество (разработчики всех уровней).

Поддержка **любых языков программирования и структур проектов**.

---

## 3. Команды CLI

Инструмент `ai-context` предоставляет следующие команды для управления контекстом и взаимодействия с ИИ:

### `ai-context init`

Инициализирует `.ai-context/` в корне проекта:
- создаёт скрытую папку `.ai-context/`,
- добавляет её в `.gitignore`,
- генерирует:
  - `.ai-context/.ai-ignore` — правила исключения файлов (аналог `.gitignore`),
  - `.ai-context/secrets.json` — для хранения URL и API-ключей (**не коммитится!**),
  - `.ai-context/system-prompt.txt` — системный промт для ИИ,
  - `.ai-context/dialog.json` — история диалога,
  - `.ai-context/context.db` — **SQLite-база с контекстом проекта (основной и единственный формат хранения)**.
- автоматически запускает индексацию проекта (`ai-context index`).

> После `init` создаются файлы:
> - `./out.txt` — полный контекст (экспорт из БД),
> - **резюме проекта автоматически генерируется и сохраняется в БД**, но **не экспортируется** — его можно получить через `compress`.

---

### `ai-context index`

Один раз сканирует проект и обновляет контекст:
- рекурсивно обходит все файлы,
- учитывает правила из `.ai-context/.ai-ignore`,
- пропускает:
  - бинарные файлы,
  - файлы > 1 МБ,
  - скрытые файлы/папки (если не разрешены в `.ai-ignore`),
- сохраняет содержание подходящих файлов в SQLite (`context.db`),
- **автоматически обновляет кэшированное резюме проекта в той же БД**.

---

### `ai-context compress [путь]`

Экспортирует **сжатое резюме проекта** (только сигнатуры функций, классов и первые строки докстрингов).

- Использует **уже проиндексированные данные из `context.db`** — **не читает файлы повторно**.
- Резюме **не перегенерируется на лету** — берётся из внутреннего кэша `project_summary`, обновлённого при последнем `index`.
- По умолчанию сохраняет в `./resume.txt`.

Пример:
```bash
ai-context compress ./resume.txt
```

### `ai-context read [путь]`
Экспортирует полный контекст из SQLite-базы в текстовый файл (например, out.txt) в формате:
```text
### FILE: путь/к/файлу ###
<содержимое>
============================================================
```

### `ai-context chat [--clear]`
Запускает интерактивный чат с ИИ:

 - автоматически загружает системный промт и актуальный контекст из БД,
 - передаёт всю историю диалога,
 - поддерживает потоковую генерацию ответа (streaming),
 - сохраняет историю в dialog.json.
 - Флаг --clear очищает историю и контекст перед запуском.
 - Используется модель из secrets.json (по умолчанию — qwen3:14b через Ollama).

### `ai-context prompt`
Открывает system-prompt.txt в системном редакторе
(должен быть указан в переменной $EDITOR или VS Code по умолчанию на Windows),
позволяя настроить стиль и поведение ИИ в чате.

### `ai-context watchdog [--stop]`
Запускает фоновый наблюдатель (daemon, демон) за изменениями в проекте:

 - отслеживает события created, modified, deleted,
 - автоматически обновляет или удаляет файлы в context.db,
 - автоматически обновляет кэш резюме при каждом изменении,
 - запускается в отдельном терминальном окне (на Windows),
 - опция --stop останавливает работающий демон.

----

## 4. Технический стек (актуально на v1)

## 4. Технический стек (актуально на v1)

| Компонент                | Технология                                                                 |
|--------------------------|----------------------------------------------------------------------------|
| Язык программирования    | Python 3.10+                                                               |
| CLI-фреймворк            | [Typer](https://typer.tiangolo.com/) + [Rich](https://rich.readthedocs.io/) |
| Игнор-правила            | [pathspec](https://pypi.org/project/pathspec/) (совместимость с `.gitignore`) |
| Файловый наблюдатель     | [watchdog](https://pypi.org/project/watchdog/)                             |
| ИИ-клиент                | [OpenAI Python SDK](https://github.com/openai/openai-python) с поддержкой Ollama через `base_url` |
| Хранение контекста       | **SQLite (`context.db`) — основной и единственный формат**; текстовые файлы (`out.txt`, `resume.txt`) — только для экспорта |
| Упаковка                 | PyInstaller (поддержка Windows, Linux, macOS — в планах)                   |
| Локальная ИИ-модель (MVP)| `qwen3:14b` или `deepseek-coder:6.7b-instruct` через Ollama (`http://localhost:11434/v1`) |
| Подсчёт токенов          | [tiktoken](https://github.com/openai/tiktoken) (с fallback на `cl100k_base`) |

---

## 5. Поддерживаемые ИИ-модели
Основная (MVP): локальная модель через Ollama
→ qwen3:14b или deepseek-coder:6.7b-instruct (но архитектура расширяема).
Будущее: OpenAI, Anthropic, Qwen и др.
Клиент использует OpenAI-совместимый API:

```python
base_url = "http://localhost:11434/v1"
api_key = "ollama"
```
**Важно**:
Все файлы в папке .ai-context/ должны быть добавлены в .gitignore.
Особенно secrets.json — никогда не коммить API-ключи!